# Uncertainty-Aware Label Refinement for Sequence Labeling
[\[paper\]](2012.10608.pdf) [\[code\]](https://github.com/jiacheng-ye/UANet)

## Motivation

CRF for label decoding is incompetent in 2 major aspects:
1. Long term label dependencies
2. Efficiency

*This is indeed of interest. Viterbi algorithm used in CRF is a DP based algorithm and end-to-end NN can potential achieve the same functionality in a more efficient way.*

## Main Idea
2-stage label decoding framework:
1. Base model predict draft labels
2. Two-stream self-attention model makes refinement based on long term dependencies.

*This reminds me of the re-ranking mechanism use to refine predicted results. For example [[Neural Ranking Models for Temporal Dependency Structure Parsing|this]] paper on dependency parsing with NN + re-ranking.*

Then, use [[What uncertainties do we need in bayesian deep learning for computervision|Bayesian NN]] to indicate labels that are with a high probability of being wrong to **prevent error propagation**.

*The idea of prevent error propagation is interesting. Variational NN needs more attention, read [[Dropout as a bayesian approximation - Representing modeluncertainty in deep learning|this paper]] for example.*

## Model Architecture

![[Pasted image 20201224231931.png]]

### Variational LSTM

[[A theoretically grounded application of dropout inrecurrent neural networks|Variational LSTM]] is used to provide a better comparison with other non-Bayesian LSTM based models. 

Embedding $\mathbf{E}$: Word-level + character-level embedding (generated through CNN).

Variational LSTM $(\mathbf{E}, \mathbf{W} = \{\mathbf{W}^g, \mathbf{W}^i, \mathbf{W}^f, \mathbf{W}^o\}, r)$:
$$
\mathbf{t}_i = \mathrm{W}^t\begin{bmatrix}\mathbf{x}_i^T\odot \mathrm{z}_x\\\mathrm{h}_{i-1}\odot\mathbf{z}_h\end{bmatrix}+\mathbf{b}^t
$$
for each gate ${t}\in\{\mathbf{g},\mathbf{i},\mathbf{f},\mathbf{o}\}$ (input modulation, input, forget, output) and $\mathbf{z}_x,\mathbf{z}_h$ are masks generated by dropout rate $r$. Then,
$$
\left\{\begin{array}{l}
\mathbf{c}_i = \phi(\mathbf{g}_i)\odot\sigma(\mathbf{i}_i)
+\mathbf{c}_{i-1}\odot\sigma(\mathbf{f}_i)\\
\mathbf{h}_i=\sigma(\mathbf{o}_i)\odot\phi(\mathbf{c}_i)\end{array}\right.
$$
with $\phi$ denoting $\tanh$ and $\sigma$ $\operatorname{sigmoid}$.

Based on the Bayesian idea, i.e. when queried a new sample $\mathbf{x}^*$,

$$
p(\mathbf{y}^*|\mathbf{x}^*) = \int p(\mathbf{y}^*|\mathbf{W},\mathbf{x}^*)p(\mathbf{W}|\mathcal{D})d\mathbf{W}
$$
where $\mathcal{D}$ stands for the datasets, posterior when inferencing a new input sequence $S$ in variational LSTM here is
$$
\mathbf{p}_i(y|S,\mathcal{D})\approx\frac{1}{M}\sum_{j=1}^M{\operatorname{Softmax}}(\mathbf{h}_i|\mathbf{W}_j)
$$

with $M$ sampled masked model weights $\mathbf{W}_j\sim q_\theta^*(\mathbf{W})$, which is the dropout distribution (Bernoulli here) that approximates $p(\mathbf{W}|\mathcal{D})$ and the draft labels are determined as
$$
y_i^* = \arg\max(\mathbf{p}_i)
$$
The uncertainty $u_i$ is calculated as the entropy of $\mathbf{p}_i$, i.e.
$$
u_i = -\sum_{c\in\{\text{the possible labels}\}} \mathbf{p}_i[c]\log\mathbf{p}_i[c]
$$
*This uncertainty measure is not as exciting as I anticipated it to be but well understandable.*

The target function measure the KL divergence between the true $p(\mathbf{W}|\mathcal{D})$. 

$$
\mathcal{L}_1 = -\frac{1}{N}\sum_{i=1}^N\log p(y_i|\mathbf{W}_j)+\frac{1-r}{2N}(||\mathbf{W}||_2^2+||\mathbf{E}||_2^2)
$$

where $\mathbf{W}_j$ is again sampled using $q_\theta^*(\mathbf{W})$ and $N$ is the length of the input sequence.

*It is hard to see why the loss represents this. The [referenced paper](https://people.eecs.berkeley.edu/~jordan/papers/variational-intro.pdf) is rather old (1999). It perhaps has been mentioned in other paper the author has cited too.*

### Two-Stream Self-Attention

Transformer with relative position encoding, i.e. replacing $\mathbf{U}_j$ when calculating $\mathbf{A}_{ij}$ with $\mathbf{R}_{i-j}$ which stands for the relative position.

Two-stream: Attention from word to word ($x2x$) and word to label ($x2l$). Then, the new attention scores are

$$
\begin{aligned}
\mathbf{A}_{i, j}^{x 2 x} =&\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q x}^{\top} \mathbf{W}_{k x} \mathbf{E}_{x_{j}}+\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q x}^{\top} \mathbf{W}_{k R} \mathbf{R}_{i-j} +\\
&\mathbf{u}_{x}^{\top} \mathbf{W}_{k x} \mathbf{E}_{x_{j}}+\mathbf{v}_{x}^{\top} \mathbf{W}_{k R} \mathbf{R}_{i-j} \\
\mathbf{A}_{i, m}^{x 2 l} =&\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q l}^{\top} \mathbf{W}_{k l} \mathbf{E}_{y_{m}^{*}}+\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q l}^{\top} \mathbf{W}_{k R} \mathbf{R}_{i-m} +\\
&\mathbf{u}_{l}^{\top} \mathbf{W}_{k l} \mathbf{E}_{y_{m}^{*}}+\mathbf{v}_{l}^{\top} \mathbf{W}_{k R} \mathbf{R}_{i-m}
\end{aligned}
$$

*Might be helpful to look at the [reference paper](https://www.aclweb.org/anthology/P19-1285/) and this [review](https://blog.csdn.net/qq_22795223/article/details/106130388) on it. The short answer is that  $\mathbf{u}_x,\mathbf{u}_l$ and $\mathbf{v}_x,\mathbf{v}_l$ are not specific to any ${x},{l}$ but only stands for a replacement of the original positional encoding based on the assumption that when evaluation on relative position, the absolute position of the word of query doesn't matter anymore.*

Then the overall rule is
$$
\begin{aligned}
\mathbf{V}_{x}&=\mathbf{E}_{x} \mathbf{W}_{x}, \mathbf{a}_{x}=\operatorname{Softmax}\left(\mathbf{A}^{x 2 x}\right) \mathbf{V}_{x} \\
\mathbf{V}_{l}&= \mathbf{E}_{y^{*}} \mathbf{W}_{l}, \mathbf{a}_{l}=\operatorname{Softmax}\left(\mathbf{A}^{x 2 l}\right) \mathbf{V}_{l} \\
\mathbf{o}_{x}&= \text { LayerNorm }\left(\operatorname{Linear}\left(\mathbf{a}_{x}\right)+\mathbf{E}_{x}\right) \\
\mathbf{o}_{l}&= \text { LayerNorm }\left(\operatorname{Linear}\left(\mathbf{a}_{l}\right)+\mathbf{E}_{y^{*}}\right) \\
\mathbf{H}_{x}&=\text { FeedForward }\left(\mathbf{o}_{x}\right) \\
\mathbf{H}_{l}&=\text { FeedForward }\left(\mathbf{o}_{l}\right)\\
\hat{y}_i&=f(\mathbf{H}_x,\mathbf{H}_l|\mathbf{E}_x,\mathbf{E}_{y_m^*})
\end{aligned}
$$

and the corresponding target function is
$$
\mathcal{L}_2 = -\sum_{i=1}^Ny_i\log\hat{y}_i
$$
where $y_i$ is a one-hot vector that is one only when $i$ is the correct label.

The output label would be $\hat{y}_i$ if $u_i\geq\Gamma$ and $y$ otherwise.

## Other Comments

*The result is not that convincing in terms of improvement in accuracy and especially efficiency. It is still necessary to look at other variational models and study the underlying theoretical foundations.*